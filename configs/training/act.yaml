# ============================================================================
# ACT - Action Chunking Transformer
# ============================================================================
# Lightweight (~80M params). Trains from scratch (no pretrained model needed).
# Good default for beginners. Works well with small datasets (50+ demos).
# Typical training: ~2 hours for 100k steps on a single GPU.
#
# Docs: https://huggingface.co/docs/lerobot/act
# ============================================================================

# -- Dataset (required) -------------------------------------------------------
# Local path to a LeRobot dataset, or a HuggingFace repo ID.
#   Examples: /workspaces/rosetta_ws/datasets/lerobot/my_dataset
#             my-hf-org/my-dataset
dataset: ""

# -- Output -------------------------------------------------------------------
# Directory where checkpoints are saved (model name appended automatically).
output_dir: /workspaces/rosetta_ws/models

# Push trained model to HuggingFace Hub. Leave empty to skip.
hub_repo_id: ""

# -- Training -----------------------------------------------------------------
batch_size: 8
steps: 100000
device: cuda
wandb: false
job_name: ""              # auto-generated if empty

# -- Multi-GPU (uncomment to enable) -----------------------------------------
# num_gpus: 2
# mixed_precision: fp16   # fp16 or bf16

# -- Model --------------------------------------------------------------------
policy_type: act

# -- ACT-specific overrides (uncomment to customize) --------------------------
# policy:
#   chunk_size: 100
#   n_action_steps: 100
#   vision_backbone: resnet18
#   dim_model: 512
#   n_heads: 8
#   n_encoder_layers: 4
#   n_decoder_layers: 1
#   use_vae: true
#   latent_dim: 32
#   kl_weight: 10.0
#   dropout: 0.1
#   optimizer_lr: 1e-5
